<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>S3 on Moselog</title>
    <link>http://localhost:1313/tags/s3/</link>
    <description>Recent content in S3 on Moselog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Jun 2014 09:10:31 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/s3/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>S3 backups</title>
      <link>http://localhost:1313/2014/06/12/s3-backups</link>
      <pubDate>Thu, 12 Jun 2014 09:10:31 +0800</pubDate>
      
      <guid>http://localhost:1313/2014/06/12/s3-backups</guid>
      <description>&lt;p&gt;We use S3 to backup various kind of files on MB. We use the very convenient backup gem for that (we still use 3.9.0).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://meskyanichi.github.io/backup/v4/&#34;&gt;http://meskyanichi.github.io/backup/v4/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But at some point it appeared that backing up our audio recording was hammering disk IO on our server, because the syncer is calculating md5 footprint for each file each time a backup happens. When you get thousands of big files that is pretty expensive process (in our case 20k files and 50G total).&lt;/p&gt;

&lt;p&gt;So I added a small trick there:&lt;/p&gt;

&lt;p&gt;in &lt;code&gt;Backup/models/backup_audio.rb&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;module Backup::Syncer::Cloud
  class Base &amp;lt; Syncer::Base
    def process_orphans
      if @orphans.is_a?(Queue)
        @orphans = @orphans.size.times.map { @orphans.shift }
      end
      &amp;quot;Older Files: #{ @orphans.count }&amp;quot;
    end
  end
end

Backup::Model.new(:backup_audio, &#39;Audio files Backup to S3&#39;) do

  before do
    system(&amp;quot;/Backup/latest_audio.sh&amp;quot;)
  end

  after do
    FileUtils.rm_rf(&amp;quot;/tmp/streams&amp;quot;)
  end

  ##
  # Amazon Simple Storage Service [Syncer]
  #
  sync_with Cloud::S3 do |s3|
    s3.access_key_id     = &amp;quot;xxx&amp;quot;
    s3.secret_access_key = &amp;quot;xxx&amp;quot;
    s3.bucket            = &amp;quot;bucket_backup&amp;quot;
    s3.region            = &amp;quot;us-east-1&amp;quot;
    s3.path              = &amp;quot;/mb_audio_backup&amp;quot;
    s3.mirror            = false
    s3.thread_count      = 50

    s3.directories do |directory|
      directory.add &amp;quot;/tmp/streams&amp;quot;
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and in &lt;code&gt;Backup/latest_audio.sh&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh
# isolate files changed in the last 3 days

TMPDIR=/tmp/streams

mkdir $TMPDIR
for i in `find /storage/audio/ -type f -cmin -4320`; do
  ln -s $i $TMPDIR
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It creates a fake backup dir with links to the files that actually changed in the last 3 days and patches the syncer to avoid flooding the logs with orphan files. When sometimes S3 upload fails on one file (and it happens from time to time for &amp;lsquo;amazonian&amp;rsquo; reason) it will be caught on the next daily backup.&lt;/p&gt;

&lt;p&gt;The result was pretty obvious on our disk usage with our daily backups:&lt;/p&gt;

&lt;img src=&#34;http://res.cloudinary.com/mosepix/image/upload/devtips/2014-06-12-s3backup.png&#34; alt=&#34;graph&#34; class=&#34;pure-img&#34; /&gt;



&lt;p&gt;in the logs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[2014/06/10 07:00:25][info] Summary:
[2014/06/10 07:00:25][info]   Transferred Files: 5
[2014/06/10 07:00:25][info]   Older Files: 22371
[2014/06/10 07:00:25][info]   Unchanged Files: 16
[2014/06/10 07:00:25][info] Syncer::Cloud::S3 Finished!
[2014/06/10 07:00:25][info] Backup for &#39;Audio files Backup to S3 (backup_audio)&#39; Completed Successfully in 00:00:22
[2014/06/10 07:00:25][info] After Hook Starting...
[2014/06/10 07:00:25][info] After Hook Finished.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>